{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23097155",
   "metadata": {},
   "source": [
    "# Hybrid Data type CNN - Regression\n",
    "\n",
    "This is a generic notebook to handle hybrid type data. By hybrid type data, we mean data where each data point has both structured features and an image. For example, A data set might contain a person's physical measurements, as well as a photo of their face. The response variable might be how attractive they are from 0 to 1. \n",
    "\n",
    "## Importing Core Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a3ebd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#I used tensorflow version 2.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f6326a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ac1978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6109187894238733593\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16740968887557702340\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5860481012838333517\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14676252416\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8030963071800696467\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e34087f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()\n",
    "\n",
    "# should be a non-empty list if you program recognizes the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2799244b",
   "metadata": {},
   "source": [
    "## Importing the Data\n",
    "\n",
    "Your dataset should be in a format such that you have one column with the filenames of the images, one column with the response variable, and the rest of your columns should be your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d3566bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in this section for your dataset\n",
    "\n",
    "dataset_filename = \"test_dataset.csv\"\n",
    "\n",
    "response_col_name = \"resp\"\n",
    "\n",
    "image_filename_col_name = \"images\"\n",
    "\n",
    "path = \"Images\" #the path where your iamges are stored. You may leave this as an empty string if your dataset contains full paths for your images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870706d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_filename)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1562566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94102, 70)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59d58c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = df[response_col_name]\n",
    "image_filenames = df[image_filename_col_name]\n",
    "\n",
    "features_df = df.drop([response_col_name, image_filename_col_name], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5446e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94102, 68)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e2c71f",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Here we will preprocess the data. By default, we will encode and scale the data. Feel free to add your own steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbed20bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94102, 68)\n",
      "(94102, 111)\n"
     ]
    }
   ],
   "source": [
    "#one-hot encoding\n",
    "print(features_df.shape)\n",
    "features_df = pd.get_dummies(features_df)\n",
    "print(features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18b544cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal scaling\n",
    "normalized_df=(features_df-features_df.mean())/features_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back the image filenames\n",
    "normalized_df[image_filename_col_name] = image_filenames\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c412370a",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "Because we may be using a large dataset, there is a chance that loading our entire dataset into memory may not be feasible. For image problems we can get around this the tensorflow class ImageDataGenerator. However, since we are using hybrid data, we also would need a generator for the non-image feature data. These would need to be wrapped up in another generator and that generator would be passed to the model for training. I tried this approach, but found lots of issues with shuffling, images getting out of order, and weird edge cases. In the end I decided to build my own generator that alliviated all these problems. It runs slower than the tensorflow solution, but I found the performance loss to be negligible when compared to the computational load of training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5c124795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import image\n",
    "def CustomGenerator(path, features_with_images_df, response_series, batch_size, im_width = image_width, im_height = image_height, im_channels = image_channels):\n",
    "    response = response_series.to_numpy()\n",
    "    \n",
    "    size = len(response)\n",
    "    \n",
    "    def GetImage(filename):\n",
    "        return image.imread( path + filename)[:,:,:im_channels]\n",
    "    \n",
    "    def GetManyImages(filenames):\n",
    "        arr = np.zeros((batch_size, im_width, im_height, im_channels))\n",
    "        for j, filename in enumerate(filenames):\n",
    "            arr[j] = GetImage(filename)\n",
    "        return arr\n",
    "    \n",
    "    features_without_images = features_with_images_df.drop(image_filename_col_name, axis = 1).to_numpy()\n",
    "    image_filenames = features_with_images_df[image_filename_col_name]\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "            resp = response[i:i + batch_size]\n",
    "            features = features_without_images[i:i + batch_size, :]\n",
    "            images = GetManyImages(image_filenames[i:i + batch_size])\n",
    "            #print(\"i:\",i)\n",
    "            yield ((features, images), resp)\n",
    "            i += batch_size\n",
    "            \n",
    "            if i >= size:\n",
    "                i = 0\n",
    "                #print('restart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f049a15",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Here we will be defining our hybrid CNN - MLP model. The images are fed through a CNN, whilst the non-image feature data is fed through an MLP. The outputs of each are combined into another MLP. Below you will need to define your hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fd179b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "def create_mlp(dim, regularizer=None):\n",
    "    \"\"\"Creates a simple two-layer MLP with inputs of the given dimension. You can change these dimension or add more layers.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=dim, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(16, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "    model.add(Dense(network_outputs, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7e6cc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Input, concatenate\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regularizer=None):\n",
    "    \"\"\"\n",
    "    Creates a CNN with the given input dimension and filter numbers.\n",
    "    \"\"\"\n",
    "    # Initialize the input shape and channel dimension, where the number of channels is the last dimension\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    " \n",
    "    # Define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    " \n",
    "    # Loop over the number of filters \n",
    "    for (i, f) in enumerate(filters):\n",
    "        # If this is the first CONV layer then set the input appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    " \n",
    "        # Create loops of CONV => RELU => BN => POOL layers\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        \n",
    "    # Final layers - flatten the volume, then Fully-Connected => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16, kernel_regularizer=regularizer)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    " \n",
    "    # Apply another fully-connected layer, this one to match the number of nodes coming out of the MLP\n",
    "    x = Dense(network_outputs, kernel_regularizer=regularizer)(x)\n",
    "    \n",
    "    #You may need to modify this for your type of problem:\n",
    "    \n",
    "    #Classification\n",
    "    #x = Activation(\"softmax\")(x)\n",
    "    \n",
    "    #Regression\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    \n",
    " \n",
    "    # Construct the CNN\n",
    "    model = Model(inputs, x)\n",
    " \n",
    "    # Return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9192881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function plots the results\n",
    "def plot_results(history):\n",
    "    met = history.history[loss_metric]\n",
    "    epochs = range(1, len(met) + 1)\n",
    "    \n",
    "    for m in metrics:\n",
    "        met = history.history[m]\n",
    "        met_val = history.history[\"val_\"+m]\n",
    "        plt.plot(epochs, met, 'g.', label='Training')\n",
    "        plt.plot(epochs, met_val, 'g', label='Validation')\n",
    "        plt.title(m)\n",
    "        plt.figure()            \n",
    "        plt.legend()\n",
    "        \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe250dfb",
   "metadata": {},
   "source": [
    "## Creating the Model\n",
    "\n",
    "Here we create a model using our model definition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0fdb23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam # Other optimisers are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f2c46b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = None #l1(0.01) you may want to use regularizer to help reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1dcb97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The regression metric your model will try to optimize. Only this metric will affect the training. \n",
    "#use another metric for classification\n",
    "loss_metric = 'mean_squared_error' \n",
    "\n",
    "metrics = [loss_metric, 'mean_absolute_error'] #The metrics your model will calculate during training. You can add other metrics to this list, but they will not affect the training. \n",
    "\n",
    "filters = (16, 32, 64) #each number here will increase the size of your CNN. The number represents the depth at that layer. \n",
    "\n",
    "image_width = 200  #the width of your image in pixels\n",
    "image_height = 200  #the height of your image in pixels\n",
    "image_channels = 3 #the number of color channels in your image (3 for RGB, 4 for RGBA)\n",
    "\n",
    "network_outputs = 8 #the number outputs both the MLP and CNN have. (They don't need to be the same, you can change them each individually)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "save_path = \"Models/run1\" #the name of your model's save path. you may have to create a Models folder. Change this to avoid overwriting models you have already trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e560a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLP and CNN models\n",
    "mlp = create_mlp(normalized_df.shape[1] - 1, reg) #take 1, because we are going to remove the image paths in the generator\n",
    "cnn = create_cnn(image_width, image_height, image_channels, filters, reg)\n",
    " \n",
    "# Create the input to the final set of layers as the output of both the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "x = Dense(network_outputs, activation=\"relu\")(combinedInput)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "\n",
    "#last layer should have something like relu for regression\n",
    "x = Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "#We are using a relu activation on the last layer for regression. Depending on your response data, you may need to use a different activation function. \n",
    "#For example, relu will not handle negative numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "58fca189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun this cell to reset the model\n",
    "\n",
    "# The final model accepts numerical data on the MLP input and images on the CNN input, outputting a single value\n",
    "\n",
    "model_main = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "# Compile the model \n",
    "opt = Adam(lr=learning_rate, decay=learning_rate / 200)\n",
    "\n",
    "model_main.compile(loss=loss_metric, metrics=metrics, optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f1a06",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "These callbacks are used to help the model. If you change your model, make sure you double check these. For example, if you use r2, you will need to set mode to max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1b24c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(mode = 'min', monitor = 'val_loss', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a6be74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "savePath = save_path\n",
    "checkpoint = ModelCheckpoint(savePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2561e3",
   "metadata": {},
   "source": [
    "## Creating the Data Generators\n",
    "\n",
    "Here we will create the data generators for both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f325fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many batches are used for each calculation. \n",
    "batch_size = 32 \n",
    "\n",
    "#The proportion of the total dataset used for training. The rest will be used for validation. \n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "53da23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_df, response, train_size = train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "54635cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This process may remove some data points at the end due to rounding, never more than the batch size. \n",
    "\n",
    "extra_train = len(y_train)%batch_size\n",
    "extra_test = len(y_test)%batch_size\n",
    "\n",
    "X_train = X_train[:-extra_train]\n",
    "y_train = y_train[:-extra_train]\n",
    "\n",
    "X_test = X_test[:-extra_test]\n",
    "y_test = y_test[:-extra_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b78bdd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test)%batch_size)\n",
    "print(len(y_train)%batch_size)\n",
    "\n",
    "# both numbers should be 0, otherwise your model may encounter an error at the end of its first epoch. \n",
    "# this is caused because the dataset may not always go evenly into the batch size. \n",
    "# The data generator should account for this, but it hasn't been fully tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ded32b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we create the generators from the data set. \n",
    "gen =    CustomGenerator(path, X_train,  y_train, batch_size)\n",
    "genVal = CustomGenerator(path, X_test,   y_test,  batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fa33e",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "If you training the model, it will continue from the where it left off unless you reset the model by reset the model_main variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fec8e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of times the training algorithm will go through the entire dataset.\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7e8f1521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 1.3135 - mean_squared_error: 1.3135 - mean_absolute_error: 0.2016INFO:tensorflow:Assets written to: Models/run1/assets\n",
      "2352/2352 [==============================] - 131s 56ms/step - loss: 1.3135 - mean_squared_error: 1.3135 - mean_absolute_error: 0.2016 - val_loss: 1.1662 - val_mean_squared_error: 1.1662 - val_mean_absolute_error: 0.1915\n",
      "Epoch 2/5\n",
      "2351/2352 [============================>.] - ETA: 0s - loss: 1.3140 - mean_squared_error: 1.3140 - mean_absolute_error: 0.2017INFO:tensorflow:Assets written to: Models/run1/assets\n",
      "2352/2352 [==============================] - 130s 55ms/step - loss: 1.3135 - mean_squared_error: 1.3135 - mean_absolute_error: 0.2016 - val_loss: 1.1662 - val_mean_squared_error: 1.1662 - val_mean_absolute_error: 0.1915\n",
      "Epoch 3/5\n",
      "2351/2352 [============================>.] - ETA: 0s - loss: 1.3140 - mean_squared_error: 1.3140 - mean_absolute_error: 0.2017INFO:tensorflow:Assets written to: Models/run1/assets\n",
      "2352/2352 [==============================] - 127s 54ms/step - loss: 1.3135 - mean_squared_error: 1.3135 - mean_absolute_error: 0.2016 - val_loss: 1.1662 - val_mean_squared_error: 1.1662 - val_mean_absolute_error: 0.1915\n",
      "Epoch 4/5\n",
      "2352/2352 [==============================] - ETA: 0s - loss: 1.3135 - mean_squared_error: 1.3135 - mean_absolute_error: 0.2016INFO:tensorflow:Assets written to: Models/run1/assets\n",
      "2352/2352 [==============================] - 128s 54ms/step - loss: 1.3135 - mean_squared_error: 1.3135 - mean_absolute_error: 0.2016 - val_loss: 1.1662 - val_mean_squared_error: 1.1662 - val_mean_absolute_error: 0.1915\n"
     ]
    }
   ],
   "source": [
    "model_history = model_main.fit(\n",
    "  x = gen,  \n",
    "  epochs = epochs, \n",
    "  steps_per_epoch = len(y_train)//batch_size,\n",
    "  verbose = 1,  \n",
    "  validation_data = genVal,\n",
    "  validation_batch_size = batch_size,\n",
    "  validation_steps = len(y_test)/batch_size,\n",
    "  callbacks = [es, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ed72a",
   "metadata": {},
   "source": [
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3353f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "16499bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "genVal = CustomGenerator(path, X_test,   y_test,  batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10254525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this many times to see predictions. \n",
    "x,y = next(genVal)\n",
    "preds = model_main.predict(x)\n",
    "df_results = pd.DataFrame({'Actual':y,'Preds':preds[:,0]})\n",
    "df_results['Difference'] = df_results['Actual'] - df_results['Preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
